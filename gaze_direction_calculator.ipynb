{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dcd82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "def calculate_gaze_vector_image(image_path, model, resize = False):\n",
    "\n",
    "    image_save_prefix = image_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if resize:\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255.0\n",
    "\n",
    "    int_image = np.expand_dims(image, axis=0)  # Add batch dimension: (1, height, width)\n",
    "    input_image = np.expand_dims(int_image, axis=-1)  # Add channel dimension: (1, height, width, 1)\n",
    "\n",
    "    # Predict mask\n",
    "    predicted_mask =  model.predict(input_image)[0, :, :, 0]  # (128, 128)\n",
    "\n",
    "    start_time = time.time()*1000\n",
    "    #scalar region\n",
    "    scalar_lower_bound = 0.2\n",
    "    scalar_upper_bound = 0.5\n",
    "    scalar_region_mask = np.logical_and(predicted_mask >= scalar_lower_bound, predicted_mask <= scalar_upper_bound).astype(np.uint8)\n",
    "\n",
    "    iris_lower_bound = 0.75\n",
    "    iris_upper_bound = 1\n",
    "    iris_region_mask = np.logical_and(predicted_mask >= iris_lower_bound, predicted_mask <= iris_upper_bound).astype(np.uint8)\n",
    "\n",
    "    # Find contours from the binary mask\n",
    "    unfiltered_scalar_contours, _ = cv2.findContours(scalar_region_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    iris_contours, _ = cv2.findContours(iris_region_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(iris_contours) == 0:\n",
    "        print(\"No iris contours found.\")\n",
    "        return None\n",
    "\n",
    "    scalar_contours = [cnt for cnt in unfiltered_scalar_contours if cv2.contourArea(cnt) > 25]\n",
    "\n",
    "    # Find the iris contour with the largest area\n",
    "    largest_iris_contour = max(iris_contours, key=cv2.contourArea)\n",
    "\n",
    "    M = cv2.moments(largest_iris_contour)\n",
    "\n",
    "    if M[\"m00\"] != 0:\n",
    "        center_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        center_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        # fallback if the area is too small\n",
    "        center_x, center_y = 0, 0\n",
    "\n",
    "    iris_center = (center_x, center_y)\n",
    "\n",
    "    all_points = np.vstack([cnt.reshape(-1, 2) for cnt in scalar_contours])\n",
    "    leftmost_idx = np.argmin(all_points[:, 0])\n",
    "    rightmost_idx = np.argmax(all_points[:, 0])\n",
    "    \n",
    "    leftmost = tuple(all_points[leftmost_idx])\n",
    "    rightmost = tuple(all_points[rightmost_idx])\n",
    "\n",
    "    print(f\"Leftmost Point: {leftmost}\")\n",
    "    print(f\"Rightmost Point: {rightmost}\")\n",
    "\n",
    "    scelar_vector =  np.array(rightmost) - np.array(leftmost)\n",
    "    middle_point = ((leftmost[0] + rightmost[0]) // 2, (leftmost[1] + rightmost[1]) // 2)\n",
    "    # Convert predicted mask to RGB to draw colored circles\n",
    "    # predicted_mask_rgb = cv2.cvtColor((predicted_mask * 255).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # # Draw circles at leftmost and rightmost points\n",
    "    # cv2.circle(predicted_mask_rgb, leftmost, radius=2, color=(255, 0, 0), thickness=-1)  # Blue circle\n",
    "    # cv2.circle(predicted_mask_rgb, rightmost, radius=2, color=(0, 0, 255), thickness=-1) # Red circle\n",
    "    # cv2.circle(predicted_mask_rgb, iris_center, radius=2, color=(0, 255, 255), thickness=-1) # Red circle\n",
    "    # cv2.circle(predicted_mask_rgb, middle_point, radius=2, color=(225, 0, 255), thickness=-1)  # Magenta circle\n",
    "    # cv2.line(predicted_mask_rgb, leftmost, rightmost, color=(0, 255, 0), thickness=1)\n",
    "    # cv2.arrowedLine(predicted_mask_rgb, middle_point, iris_center, color=(255, 0, 0), thickness=1, tipLength=0.5)\n",
    "\n",
    "    # # Display the mask with circles\n",
    "    # plt.figure(figsize=(8, 8))\n",
    "    # plt.imshow(predicted_mask_rgb)\n",
    "    # plt.title('Predicted Mask with Circles')\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    # # Create the directory if it doesn't exist\n",
    "    # output_dir = \"gaze_vector_prediction\"\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # # Define the output file path\n",
    "    # output_file_path = os.path.join(output_dir, image_save_prefix+\"_vectors.png\")\n",
    "\n",
    "    # # Save the image\n",
    "    # cv2.imwrite(output_file_path, cv2.cvtColor(predicted_mask_rgb, cv2.COLOR_RGB2BGR))\n",
    "    # print(f\"Image saved to {output_file_path}\")\n",
    "    iris_center_vector = np.array(iris_center)\n",
    "    middle_point_vector = np.array(middle_point)\n",
    "    end_time = time.time()*1000\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
    "    return iris_center_vector - middle_point_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "058d0ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "Leftmost Point: (np.int32(33), np.int32(98))\n",
      "Rightmost Point: (np.int32(107), np.int32(87))\n",
      "Time taken: 0.00 seconds\n",
      "[ 12 -14]\n"
     ]
    }
   ],
   "source": [
    "image_dir_path =  '/home/yasas/GazeEstimation/openEDS/openEDS/test/images'\n",
    "image_files = sorted(os.listdir(image_dir_path))\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return 1 - (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "# Now load the model properly\n",
    "# model = load_model('light_weight_unet_gaze_estimation_model.h5', custom_objects={'dice_loss': dice_loss})\n",
    "model = load_model('light_weight_unet_gaze_estimation_model_2.h5', custom_objects={'dice_loss': dice_loss})\n",
    "model_2 = load_model('light_weight_unet_gaze_estimation_model.h5', custom_objects={'dice_loss': dice_loss})\n",
    "\n",
    "# print(calculate_gaze_vector_image('/home/yasas/GazeEstimation/openEDS/openEDS/test/images/000170.png', model , resize= False))\n",
    "print(calculate_gaze_vector_image('/home/yasas/GazeEstimation/openEDS/openEDS/test/images/000000.png', model_2, resize= True))\n",
    "# skip = 741\n",
    "\n",
    "# directions = {}\n",
    "\n",
    "# for image_file in image_files:\n",
    "#     image_path = os.path.join(image_dir_path, image_file)\n",
    "#     print(image_path)\n",
    "#     print(f\"Processing {image_path}...\")\n",
    "#     direction_vector = calculate_gaze_vector_image(image_path, model)\n",
    "#     if(direction_vector is None):\n",
    "#         direction_vector = np.array([0, 0])\n",
    "#     else:\n",
    "#         direction_vector = np.array(direction_vector)\n",
    "#         norm = np.linalg.norm(direction_vector)\n",
    "#         if norm != 0:\n",
    "#             direction_vector = direction_vector / norm\n",
    "#     directions[image_path.split('/')[-1]] = direction_vector\n",
    "#     with open(\"directions.txt\", \"a\") as file:\n",
    "#         file.write(f\"{image_path.split('/')[-1]}: {direction_vector.tolist()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71a21c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leftmost Point: (np.int32(33), np.int32(86))\n",
      "Rightmost Point: (np.int32(108), np.int32(93))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -6 -15]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "def calculate_gaze_vector_from_lable_img(label_path):\n",
    "    label = np.load(label_path)\n",
    "    label = cv2.resize(label, (128, 128))\n",
    "    label = label / np.max(label)\n",
    "\n",
    "    scalar_lower_bound = 0.2\n",
    "    scalar_upper_bound = 0.5\n",
    "    scalar_region_mask = np.logical_and(label >= scalar_lower_bound, label <= scalar_upper_bound).astype(np.uint8)\n",
    "\n",
    "    iris_lower_bound = 0.75\n",
    "    iris_upper_bound = 1\n",
    "    iris_region_mask = np.logical_and(label >= iris_lower_bound, label <= iris_upper_bound).astype(np.uint8)\n",
    "\n",
    "    # Find contours from the binary mask\n",
    "    unfiltered_scalar_contours, _ = cv2.findContours(scalar_region_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    iris_contours, _ = cv2.findContours(iris_region_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(iris_contours) == 0:\n",
    "        print(\"No iris contours found.\")\n",
    "        return None\n",
    "\n",
    "    scalar_contours = [cnt for cnt in unfiltered_scalar_contours if cv2.contourArea(cnt) > 25]\n",
    "\n",
    "    # Find the iris contour with the largest area\n",
    "    largest_iris_contour = max(iris_contours, key=cv2.contourArea)\n",
    "\n",
    "    M = cv2.moments(largest_iris_contour)\n",
    "\n",
    "    if M[\"m00\"] != 0:\n",
    "        center_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        center_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        # fallback if the area is too small\n",
    "        center_x, center_y = 0, 0\n",
    "\n",
    "    iris_center = (center_x, center_y)\n",
    "\n",
    "    # Initialize leftmost and rightmost points\n",
    "    leftmost = (128, 128)\n",
    "    rightmost = (0, 0)\n",
    "\n",
    "    # Find extreme points from all contours\n",
    "    for contour in scalar_contours:\n",
    "        for point in contour:\n",
    "            x, y = point[0]\n",
    "            if x < leftmost[0]:\n",
    "                leftmost = (x, y)\n",
    "            if x > rightmost[0]:\n",
    "                rightmost = (x, y)\n",
    "\n",
    "    print(f\"Leftmost Point: {leftmost}\")\n",
    "    print(f\"Rightmost Point: {rightmost}\")\n",
    "\n",
    "    scelar_vector =  np.array(rightmost) - np.array(leftmost)\n",
    "    middle_point = ((leftmost[0] + rightmost[0]) // 2, (leftmost[1] + rightmost[1]) // 2)\n",
    "    # Convert predicted mask to RGB to draw colored circles\n",
    "    predicted_mask_rgb = cv2.cvtColor((label * 255).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Draw circles at leftmost and rightmost points\n",
    "    cv2.circle(predicted_mask_rgb, leftmost, radius=2, color=(255, 0, 0), thickness=-1)  # Blue circle\n",
    "    cv2.circle(predicted_mask_rgb, rightmost, radius=2, color=(0, 0, 255), thickness=-1) # Red circle\n",
    "    cv2.circle(predicted_mask_rgb, iris_center, radius=2, color=(0, 255, 255), thickness=-1) # Red circle\n",
    "    cv2.circle(predicted_mask_rgb, middle_point, radius=2, color=(225, 0, 255), thickness=-1)  # Magenta circle\n",
    "    cv2.line(predicted_mask_rgb, leftmost, rightmost, color=(0, 255, 0), thickness=1)\n",
    "    cv2.arrowedLine(predicted_mask_rgb, middle_point, iris_center, color=(255, 0, 0), thickness=1, tipLength=0.5)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(predicted_mask_rgb)\n",
    "    plt.title('Predicted Mask with Circles')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    iris_center_vector = np.array(iris_center)\n",
    "    middle_point_vector = np.array(middle_point)\n",
    "    return iris_center_vector - middle_point_vector\n",
    "\n",
    "\n",
    "image_label_path =  '/home/yasas/GazeEstimation/openEDS/openEDS/test/labels'\n",
    "print(calculate_gaze_vector_from_lable_img('/home/yasas/GazeEstimation/openEDS/openEDS/test/labels/000170.npy'))\n",
    "\n",
    "image_files = sorted(os.listdir(image_label_path))\n",
    "\n",
    "\n",
    "# for image_file in image_files:\n",
    "#     image_path = os.path.join(image_label_path, image_file)\n",
    "#     print(image_path)\n",
    "#     print(f\"Processing {image_path}...\")\n",
    "#     calculate_gaze_vector_from_lable_img(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
