{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5dcd82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 13:27:12.043532: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-29 13:27:12.058740: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745913432.081780 1186154 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745913432.089055 1186154 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745913432.108025 1186154 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745913432.108051 1186154 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745913432.108053 1186154 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745913432.108055 1186154 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-29 13:27:12.114052: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "def calculate_gaze_vector_image(image_path, model):\n",
    "    image_save_prefix = image_path.split('/')[-1].split('.')[0]\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Resize and normalize\n",
    "    image_resized = cv2.resize(image, (128, 128))\n",
    "    image_normalized = image_resized / 255.0\n",
    "\n",
    "    # Prepare input for model\n",
    "    input_image = np.expand_dims(image_normalized, axis=0)  # (1, 128, 128)\n",
    "    input_image = np.expand_dims(input_image, axis=-1)      # (1, 128, 128, 1)\n",
    "\n",
    "    # Display the mask with circles\n",
    "    # plt.figure(figsize=(8, 8))\n",
    "    # plt.imshow(image_resized)\n",
    "    # plt.title('Predicted Mask with Circles')\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    # Predict mask\n",
    "    predicted_mask =  model.predict(input_image)[0, :, :, 0]  # (128, 128)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(predicted_mask)\n",
    "    plt.title('Predicted Mask with Circles')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    #scalar region\n",
    "    scalar_lower_bound = 0.2\n",
    "    scalar_upper_bound = 0.5\n",
    "    scalar_region_mask = np.logical_and(predicted_mask >= scalar_lower_bound, predicted_mask <= scalar_upper_bound).astype(np.uint8)\n",
    "\n",
    "    iris_lower_bound = 0.75\n",
    "    iris_upper_bound = 1\n",
    "    iris_region_mask = np.logical_and(predicted_mask >= iris_lower_bound, predicted_mask <= iris_upper_bound).astype(np.uint8)\n",
    "\n",
    "    # Find contours from the binary mask\n",
    "    unfiltered_scalar_contours, _ = cv2.findContours(scalar_region_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    iris_contours, _ = cv2.findContours(iris_region_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(iris_contours) == 0:\n",
    "        print(\"No iris contours found.\")\n",
    "        return None\n",
    "\n",
    "    scalar_contours = [cnt for cnt in unfiltered_scalar_contours if cv2.contourArea(cnt) > 25]\n",
    "\n",
    "    # Find the iris contour with the largest area\n",
    "    largest_iris_contour = max(iris_contours, key=cv2.contourArea)\n",
    "\n",
    "    M = cv2.moments(largest_iris_contour)\n",
    "\n",
    "    if M[\"m00\"] != 0:\n",
    "        center_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        center_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        # fallback if the area is too small\n",
    "        center_x, center_y = 0, 0\n",
    "\n",
    "    iris_center = (center_x, center_y)\n",
    "\n",
    "    # Initialize leftmost and rightmost points\n",
    "    leftmost = (128, 128)\n",
    "    rightmost = (0, 0)\n",
    "\n",
    "    # Find extreme points from all contours\n",
    "    for contour in scalar_contours:\n",
    "        for point in contour:\n",
    "            x, y = point[0]\n",
    "            if x < leftmost[0]:\n",
    "                leftmost = (x, y)\n",
    "            if x > rightmost[0]:\n",
    "                rightmost = (x, y)\n",
    "\n",
    "    print(f\"Leftmost Point: {leftmost}\")\n",
    "    print(f\"Rightmost Point: {rightmost}\")\n",
    "\n",
    "    scelar_vector =  np.array(rightmost) - np.array(leftmost)\n",
    "    middle_point = ((leftmost[0] + rightmost[0]) // 2, (leftmost[1] + rightmost[1]) // 2)\n",
    "    # Convert predicted mask to RGB to draw colored circles\n",
    "    predicted_mask_rgb = cv2.cvtColor((predicted_mask * 255).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Draw circles at leftmost and rightmost points\n",
    "    cv2.circle(predicted_mask_rgb, leftmost, radius=2, color=(255, 0, 0), thickness=-1)  # Blue circle\n",
    "    cv2.circle(predicted_mask_rgb, rightmost, radius=2, color=(0, 0, 255), thickness=-1) # Red circle\n",
    "    cv2.circle(predicted_mask_rgb, iris_center, radius=2, color=(0, 255, 255), thickness=-1) # Red circle\n",
    "    cv2.circle(predicted_mask_rgb, middle_point, radius=2, color=(225, 0, 255), thickness=-1)  # Magenta circle\n",
    "    cv2.line(predicted_mask_rgb, leftmost, rightmost, color=(0, 255, 0), thickness=1)\n",
    "    cv2.arrowedLine(predicted_mask_rgb, middle_point, iris_center, color=(255, 0, 0), thickness=1, tipLength=0.1)\n",
    "\n",
    "    # Display the mask with circles\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(predicted_mask_rgb)\n",
    "    plt.title('Predicted Mask with Circles')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    output_dir = \"gaze_vector_prediction\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Define the output file path\n",
    "    output_file_path = os.path.join(output_dir, image_save_prefix+\"_vectors.png\")\n",
    "\n",
    "    # Save the image\n",
    "    cv2.imwrite(output_file_path, cv2.cvtColor(predicted_mask_rgb, cv2.COLOR_RGB2BGR))\n",
    "    print(f\"Image saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir_path =  '/home/yasas/GazeEstimation/openEDS/openEDS/test/images'\n",
    "image_files = sorted(os.listdir(image_dir_path))\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return 1 - (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "# Now load the model properly\n",
    "model = load_model('light_weight_unet_gaze_estimation_model.h5', custom_objects={'dice_loss': dice_loss})\n",
    "\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(image_dir_path, image_file)\n",
    "    print(image_path)\n",
    "    print(f\"Processing {image_path}...\")\n",
    "    calculate_gaze_vector_image(image_path, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
