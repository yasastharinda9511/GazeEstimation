{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5dcd82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 16:21:17.179508: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-12 16:21:17.361261: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747047077.552696   45551 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747047077.573653   45551 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747047077.716193   45551 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747047077.716227   45551 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747047077.716228   45551 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747047077.716229   45551 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-12 16:21:17.735583: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "def calculate_gaze_vector_image(image_path, model, resize = False):\n",
    "\n",
    "    image_save_prefix = image_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if resize:\n",
    "        image = cv2.resize(image, (128, 128))\n",
    "        image = image / 255.0\n",
    "\n",
    "    int_image = np.expand_dims(image, axis=0)  # Add batch dimension: (1, height, width)\n",
    "    input_image = np.expand_dims(int_image, axis=-1)  # Add channel dimension: (1, height, width, 1)\n",
    "\n",
    "    # Predict mask\n",
    "    predicted_mask =  model.predict(input_image)[0, :, :, 0]  # (128, 128)\n",
    "\n",
    "    start_time = time.time()*1000\n",
    "    #scalar region\n",
    "    scalar_lower_bound = 0.2\n",
    "    scalar_upper_bound = 0.5\n",
    "    scalar_region_mask = np.logical_and(predicted_mask >= scalar_lower_bound, predicted_mask <= scalar_upper_bound).astype(np.uint8)\n",
    "\n",
    "    iris_lower_bound = 0.75\n",
    "    iris_upper_bound = 1\n",
    "    iris_region_mask = np.logical_and(predicted_mask >= iris_lower_bound, predicted_mask <= iris_upper_bound).astype(np.uint8)\n",
    "\n",
    "    # Find contours from the binary mask\n",
    "    unfiltered_scalar_contours, _ = cv2.findContours(scalar_region_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    iris_contours, _ = cv2.findContours(iris_region_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(iris_contours) == 0:\n",
    "        print(\"No iris contours found.\")\n",
    "        return None\n",
    "\n",
    "    scalar_contours = [cnt for cnt in unfiltered_scalar_contours if cv2.contourArea(cnt) > 25]\n",
    "\n",
    "    # Find the iris contour with the largest area\n",
    "    largest_iris_contour = max(iris_contours, key=cv2.contourArea)\n",
    "\n",
    "    M = cv2.moments(largest_iris_contour)\n",
    "\n",
    "    if M[\"m00\"] != 0:\n",
    "        center_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        center_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        # fallback if the area is too small\n",
    "        center_x, center_y = 0, 0\n",
    "\n",
    "    iris_center = (center_x, center_y)\n",
    "\n",
    "    all_points = np.vstack([cnt.reshape(-1, 2) for cnt in scalar_contours])\n",
    "    leftmost_idx = np.argmin(all_points[:, 0])\n",
    "    rightmost_idx = np.argmax(all_points[:, 0])\n",
    "    \n",
    "    leftmost = tuple(all_points[leftmost_idx])\n",
    "    rightmost = tuple(all_points[rightmost_idx])\n",
    "\n",
    "    print(f\"Leftmost Point: {leftmost}\")\n",
    "    print(f\"Rightmost Point: {rightmost}\")\n",
    "\n",
    "    scelar_vector =  np.array(rightmost) - np.array(leftmost)\n",
    "    middle_point = ((leftmost[0] + rightmost[0]) // 2, (leftmost[1] + rightmost[1]) // 2)\n",
    "    # Convert predicted mask to RGB to draw colored circles\n",
    "    # predicted_mask_rgb = cv2.cvtColor((predicted_mask * 255).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # # Draw circles at leftmost and rightmost points\n",
    "    # cv2.circle(predicted_mask_rgb, leftmost, radius=2, color=(255, 0, 0), thickness=-1)  # Blue circle\n",
    "    # cv2.circle(predicted_mask_rgb, rightmost, radius=2, color=(0, 0, 255), thickness=-1) # Red circle\n",
    "    # cv2.circle(predicted_mask_rgb, iris_center, radius=2, color=(0, 255, 255), thickness=-1) # Red circle\n",
    "    # cv2.circle(predicted_mask_rgb, middle_point, radius=2, color=(225, 0, 255), thickness=-1)  # Magenta circle\n",
    "    # cv2.line(predicted_mask_rgb, leftmost, rightmost, color=(0, 255, 0), thickness=1)\n",
    "    # cv2.arrowedLine(predicted_mask_rgb, middle_point, iris_center, color=(255, 0, 0), thickness=1, tipLength=0.5)\n",
    "\n",
    "    # # Display the mask with circles\n",
    "    # plt.figure(figsize=(8, 8))\n",
    "    # plt.imshow(predicted_mask_rgb)\n",
    "    # plt.title('Predicted Mask with Circles')\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    # # Create the directory if it doesn't exist\n",
    "    # output_dir = \"gaze_vector_prediction\"\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # # Define the output file path\n",
    "    # output_file_path = os.path.join(output_dir, image_save_prefix+\"_vectors.png\")\n",
    "\n",
    "    # # Save the image\n",
    "    # cv2.imwrite(output_file_path, cv2.cvtColor(predicted_mask_rgb, cv2.COLOR_RGB2BGR))\n",
    "    # print(f\"Image saved to {output_file_path}\")\n",
    "    iris_center_vector = np.array(iris_center)\n",
    "    middle_point_vector = np.array(middle_point)\n",
    "    end_time = time.time()*1000\n",
    "    print(f\"Time taken: {end_time - start_time} ms\")\n",
    "    return iris_center_vector - middle_point_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058d0ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747047085.652696   45551 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1033 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_45551/1183018150.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m1\u001b[39m - (\u001b[32m2.\u001b[39m * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Now load the model properly\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# model = load_model('light_weight_unet_gaze_estimation_model.h5', custom_objects={'dice_loss': dice_loss})\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m model = load_model(\u001b[33m'light_weight_unet_gaze_estimation_model_2.h5'\u001b[39m, custom_objects={\u001b[33m'dice_loss'\u001b[39m: dice_loss})\n\u001b[32m     12\u001b[39m model_2 = load_model(\u001b[33m'light_weight_unet_gaze_estimation_model.h5'\u001b[39m, custom_objects={\u001b[33m'dice_loss'\u001b[39m: dice_loss})\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# print(calculate_gaze_vector_image('/home/yasas/GazeEstimation/openEDS/openEDS/test/images/000170.png', model , resize= False))\u001b[39;00m\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/saving/saving_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    192\u001b[39m             compile=compile,\n\u001b[32m    193\u001b[39m             safe_mode=safe_mode,\n\u001b[32m    194\u001b[39m         )\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m str(filepath).endswith((\u001b[33m\".h5\"\u001b[39m, \u001b[33m\".hdf5\"\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m             filepath, custom_objects=custom_objects, compile=compile\n\u001b[32m    198\u001b[39m         )\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m str(filepath).endswith(\u001b[33m\".keras\"\u001b[39m):\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(filepath, custom_objects, compile)\u001b[39m\n\u001b[32m    188\u001b[39m                         \u001b[33m\"optimizer.\"\u001b[39m\n\u001b[32m    189\u001b[39m                     )\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    191\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m             f.close()\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/legacy/saving/saving_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(config, custom_objects)\u001b[39m\n\u001b[32m     84\u001b[39m     \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[32m     86\u001b[39m     config = _find_replace_nested_dict(config, \u001b[33m\"keras.\"\u001b[39m, \u001b[33m\"keras.\"\u001b[39m)\n\u001b[32m     87\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     return serialization.deserialize_keras_object(\n\u001b[32m     89\u001b[39m         config,\n\u001b[32m     90\u001b[39m         module_objects=MODULE_OBJECTS.ALL_OBJECTS,\n\u001b[32m     91\u001b[39m         custom_objects=custom_objects,\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/legacy/saving/serialization.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[39m\n\u001b[32m    491\u001b[39m                 cls_config, \u001b[33m\"keras.\"\u001b[39m, \u001b[33m\"keras.\"\u001b[39m\n\u001b[32m    492\u001b[39m             )\n\u001b[32m    493\u001b[39m \n\u001b[32m    494\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"custom_objects\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m arg_spec.args:\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m                 deserialized_obj = cls.from_config(\n\u001b[32m    496\u001b[39m                     cls_config,\n\u001b[32m    497\u001b[39m                     custom_objects={\n\u001b[32m    498\u001b[39m                         **object_registration.GLOBAL_CUSTOM_OBJECTS,\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/models/model.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    583\u001b[39m             \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[32m    584\u001b[39m             \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[32m    585\u001b[39m             \u001b[38;5;28;01mfrom\u001b[39;00m keras.src.models.functional \u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[32m    586\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m587\u001b[39m             return functional_from_config(\n\u001b[32m    588\u001b[39m                 cls, config, custom_objects=custom_objects\n\u001b[32m    589\u001b[39m             )\n\u001b[32m    590\u001b[39m \n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/models/functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    576\u001b[39m                         process_node(layer, node_data)\n\u001b[32m    577\u001b[39m \n\u001b[32m    578\u001b[39m                     \u001b[38;5;66;03m# If the node does not have all inbound layers\u001b[39;00m\n\u001b[32m    579\u001b[39m                     \u001b[38;5;66;03m# available, stop processing and continue later\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m                     \u001b[38;5;28;01mexcept\u001b[39;00m IndexError:\n\u001b[32m    581\u001b[39m                         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    582\u001b[39m \n\u001b[32m    583\u001b[39m                     node_index += \u001b[32m1\u001b[39m\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/models/functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(layer, node_data)\u001b[39m\n\u001b[32m    502\u001b[39m         \"\"\"\n\u001b[32m    503\u001b[39m         args, kwargs = deserialize_node(node_data, created_layers)\n\u001b[32m    504\u001b[39m         \u001b[38;5;66;03m# Call layer on its inputs, thus creating the node\u001b[39;00m\n\u001b[32m    505\u001b[39m         \u001b[38;5;66;03m# and building the layer if needed.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m506\u001b[39m         layer(*args, **kwargs)\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    828\u001b[39m \n\u001b[32m    829\u001b[39m         \u001b[38;5;66;03m################\u001b[39;00m\n\u001b[32m    830\u001b[39m         \u001b[38;5;66;03m# 4. Call build\u001b[39;00m\n\u001b[32m    831\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m self._open_name_scope():\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m             self._maybe_build(call_spec)\n\u001b[32m    833\u001b[39m \n\u001b[32m    834\u001b[39m         \u001b[38;5;66;03m##########################\u001b[39;00m\n\u001b[32m    835\u001b[39m         \u001b[38;5;66;03m# 5. Infer training value\u001b[39;00m\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, call_spec)\u001b[39m\n\u001b[32m   1390\u001b[39m                 shapes_dict=shapes_dict,\n\u001b[32m   1391\u001b[39m                 call_spec=call_spec,\n\u001b[32m   1392\u001b[39m                 class_name=self.__class__.__name__,\n\u001b[32m   1393\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1394\u001b[39m             self.build(**shapes_dict)\n\u001b[32m   1395\u001b[39m             \u001b[38;5;66;03m# Check input spec again (after build, since self.input_spec\u001b[39;00m\n\u001b[32m   1396\u001b[39m             \u001b[38;5;66;03m# may have been updated\u001b[39;00m\n\u001b[32m   1397\u001b[39m             self._assert_input_compatibility(call_spec.first_arg)\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    226\u001b[39m         @wraps(original_build_method)\n\u001b[32m    227\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m build_wrapper(*args, **kwargs):\n\u001b[32m    228\u001b[39m             \u001b[38;5;28;01mwith\u001b[39;00m obj._open_name_scope():\n\u001b[32m    229\u001b[39m                 obj._path = current_path()\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m                 original_build_method(*args, **kwargs)\n\u001b[32m    231\u001b[39m             \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[32m    232\u001b[39m             signature = inspect.signature(original_build_method)\n\u001b[32m    233\u001b[39m             obj._build_shapes_dict = signature.bind(*args, **kwargs).arguments\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, input_shape)\u001b[39m\n\u001b[32m    191\u001b[39m         \u001b[38;5;66;03m# compute_output_shape contains some validation logic for the input\u001b[39;00m\n\u001b[32m    192\u001b[39m         \u001b[38;5;66;03m# shape, and make sure the output shape has all positive dimensions.\u001b[39;00m\n\u001b[32m    193\u001b[39m         self.compute_output_shape(input_shape)\n\u001b[32m    194\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         self._kernel = self.add_weight(\n\u001b[32m    196\u001b[39m             name=\u001b[33m\"kernel\"\u001b[39m,\n\u001b[32m    197\u001b[39m             shape=kernel_shape,\n\u001b[32m    198\u001b[39m             initializer=self.kernel_initializer,\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/layers/layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, shape, initializer, dtype, trainable, autocast, regularizer, constraint, aggregation, name)\u001b[39m\n\u001b[32m    543\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    544\u001b[39m                 initializer = \u001b[33m\"zeros\"\u001b[39m\n\u001b[32m    545\u001b[39m         initializer = initializers.get(initializer)\n\u001b[32m    546\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m backend.name_scope(self.name, caller=self):\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m             variable = backend.Variable(\n\u001b[32m    548\u001b[39m                 initializer=initializer,\n\u001b[32m    549\u001b[39m                 shape=shape,\n\u001b[32m    550\u001b[39m                 dtype=dtype,\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/backend/common/variables.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, initializer, shape, dtype, trainable, autocast, aggregation, name)\u001b[39m\n\u001b[32m    182\u001b[39m                 )\n\u001b[32m    183\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    184\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m callable(initializer):\n\u001b[32m    185\u001b[39m                 self._shape = self._validate_shape(shape)\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m                 self._initialize_with_initializer(initializer)\n\u001b[32m    187\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m                 self._initialize(initializer)\n\u001b[32m    189\u001b[39m                 self._shape = self._validate_shape(self._value.shape)\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, initializer)\u001b[39m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _initialize_with_initializer(self, initializer):\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         self._initialize(\u001b[38;5;28;01mlambda\u001b[39;00m: initializer(self._shape, dtype=self._dtype))\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _initialize(self, value):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m         self._value = tf.Variable(\n\u001b[32m     40\u001b[39m             value,\n\u001b[32m     41\u001b[39m             dtype=self._dtype,\n\u001b[32m     42\u001b[39m             trainable=self.trainable,\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/tensorflow/python/ops/variables.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    195\u001b[39m   @traceback_utils.filter_traceback\n\u001b[32m    196\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m __call__(cls, *args, **kwargs):\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hasattr(cls, \u001b[33m\"_variable_call\"\u001b[39m) \u001b[38;5;28;01mand\u001b[39;00m callable(cls._variable_call):\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m       variable_call = cls._variable_call(*args, **kwargs)\n\u001b[32m    199\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m variable_call \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    200\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m variable_call\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m super(VariableMetaclass, cls).__call__(*args, **kwargs)\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/tensorflow/python/ops/variables.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape, experimental_enable_variable_lifting, **kwargs)\u001b[39m\n\u001b[32m   1226\u001b[39m \n\u001b[32m   1227\u001b[39m     \u001b[38;5;66;03m# Reset `aggregation` that is explicitly set as `None` to the enum NONE.\u001b[39;00m\n\u001b[32m   1228\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m aggregation \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1229\u001b[39m       aggregation = VariableAggregation.NONE\n\u001b[32m-> \u001b[39m\u001b[32m1230\u001b[39m     return previous_getter(\n\u001b[32m   1231\u001b[39m         initial_value=initial_value,\n\u001b[32m   1232\u001b[39m         trainable=trainable,\n\u001b[32m   1233\u001b[39m         validate_shape=validate_shape,\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/tensorflow/python/ops/variables.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(**kws)\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1223\u001b[39m     previous_getter = \u001b[38;5;28;01mlambda\u001b[39;00m **kws: default_variable_creator_v2(\u001b[38;5;28;01mNone\u001b[39;00m, **kws)\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/tensorflow/python/ops/variables.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(next_creator, **kwds)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m default_variable_creator_v2(next_creator=\u001b[38;5;28;01mNone\u001b[39;00m, **kwds):\n\u001b[32m     49\u001b[39m   \u001b[38;5;28;01mfrom\u001b[39;00m tensorflow.python.ops \u001b[38;5;28;01mimport\u001b[39;00m resource_variable_ops  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[32m     50\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m   return resource_variable_ops.default_variable_creator_v2(\n\u001b[32m     52\u001b[39m       next_creator=next_creator, **kwds)\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(next_creator, **kwargs)\u001b[39m\n\u001b[32m    355\u001b[39m   shape = kwargs.get(\u001b[33m\"shape\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    356\u001b[39m   experimental_enable_variable_lifting = kwargs.get(\n\u001b[32m    357\u001b[39m       \u001b[33m\"experimental_enable_variable_lifting\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    358\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m   return ResourceVariable(\n\u001b[32m    360\u001b[39m       initial_value=initial_value,\n\u001b[32m    361\u001b[39m       trainable=trainable,\n\u001b[32m    362\u001b[39m       validate_shape=validate_shape,\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/tensorflow/python/ops/variables.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hasattr(cls, \u001b[33m\"_variable_call\"\u001b[39m) \u001b[38;5;28;01mand\u001b[39;00m callable(cls._variable_call):\n\u001b[32m    198\u001b[39m       variable_call = cls._variable_call(*args, **kwargs)\n\u001b[32m    199\u001b[39m       \u001b[38;5;28;01mif\u001b[39;00m variable_call \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    200\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m variable_call\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m super(VariableMetaclass, cls).__call__(*args, **kwargs)\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape, handle, experimental_enable_variable_lifting)\u001b[39m\n\u001b[32m   1872\u001b[39m                              shape=shape,\n\u001b[32m   1873\u001b[39m                              dtype=dtype,\n\u001b[32m   1874\u001b[39m                              handle=handle)\n\u001b[32m   1875\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1876\u001b[39m       self._init_from_args(\n\u001b[32m   1877\u001b[39m           initial_value=initial_value,\n\u001b[32m   1878\u001b[39m           trainable=trainable,\n\u001b[32m   1879\u001b[39m           collections=collections,\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape, validate_shape, experimental_enable_variable_lifting)\u001b[39m\n\u001b[32m   2056\u001b[39m                 s=[compat.as_bytes(\u001b[33m\"loc:@%s\"\u001b[39m % handle_name)]))\n\u001b[32m   2057\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m ops.get_default_graph()._attr_scope({\u001b[33m\"_class\"\u001b[39m: attr}):\n\u001b[32m   2058\u001b[39m           \u001b[38;5;28;01mwith\u001b[39;00m ops.name_scope(\u001b[33m\"Initializer\"\u001b[39m), device_context_manager(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   2059\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m init_from_fn:\n\u001b[32m-> \u001b[39m\u001b[32m2060\u001b[39m               initial_value = initial_value()\n\u001b[32m   2061\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m isinstance(initial_value, trackable.CheckpointInitialValue):\n\u001b[32m   2062\u001b[39m               self._maybe_initialize_trackable()\n\u001b[32m   2063\u001b[39m               self._update_uid = initial_value.checkpoint_position.restore_uid\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/core.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         self._initialize(\u001b[38;5;28;01mlambda\u001b[39;00m: initializer(self._shape, dtype=self._dtype))\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/initializers/random_initializers.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, shape, dtype)\u001b[39m\n\u001b[32m    302\u001b[39m                 shape, mean=\u001b[32m0.0\u001b[39m, stddev=stddev, dtype=dtype, seed=self.seed\n\u001b[32m    303\u001b[39m             )\n\u001b[32m    304\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    305\u001b[39m             limit = math.sqrt(\u001b[32m3.0\u001b[39m * scale)\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m             return random.uniform(\n\u001b[32m    307\u001b[39m                 shape, minval=-limit, maxval=limit, dtype=dtype, seed=self.seed\n\u001b[32m    308\u001b[39m             )\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/random.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(shape, minval, maxval, dtype, seed)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m uniform(shape, minval=\u001b[32m0.0\u001b[39m, maxval=\u001b[32m1.0\u001b[39m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, seed=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     32\u001b[39m     dtype = dtype \u001b[38;5;28;01mor\u001b[39;00m floatx()\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     seed = _cast_seed(draw_seed(seed))\n\u001b[32m     34\u001b[39m     return tf.random.stateless_uniform(\n\u001b[32m     35\u001b[39m         shape=shape,\n\u001b[32m     36\u001b[39m         minval=tf.cast(minval, dtype),\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/random.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Ref: https://www.tensorflow.org/api_docs/python/tf/random\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m standardize_dtype(seed.dtype) == \u001b[33m\"int32\"\u001b[39m:\n\u001b[32m     17\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m seed\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m         seed = tf.cast(tf.math.floormod(seed, tf.int32.max - \u001b[32m1\u001b[39m), dtype=\u001b[33m\"int32\"\u001b[39m)\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m seed\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m op(*args, **kwargs)\n\u001b[32m    143\u001b[39m     bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m     bound_arguments.apply_defaults()\n\u001b[32m    145\u001b[39m     bound_kwargs = bound_arguments.arguments\n",
      "\u001b[32m~/GazeEstimation/venv/lib/python3.12/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, name)\u001b[39m\n\u001b[32m   4174\u001b[39m         _ctx, \u001b[33m\"FloorMod\"\u001b[39m, name, x, y)\n\u001b[32m   4175\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   4176\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   4177\u001b[39m       _ops.raise_from_not_ok_status(e, name)\n\u001b[32m-> \u001b[39m\u001b[32m4178\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   4179\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   4180\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   4181\u001b[39m       _result = _dispatcher_for_floor_mod(\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "image_dir_path =  '/home/yasas/GazeEstimation/openEDS/openEDS/test/images'\n",
    "image_files = sorted(os.listdir(image_dir_path))\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return 1 - (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "# Now load the model properly\n",
    "# model = load_model('light_weight_unet_gaze_estimation_model.h5', custom_objects={'dice_loss': dice_loss})\n",
    "model = load_model('light_weight_unet_gaze_estimation_model_2.h5', custom_objects={'dice_loss': dice_loss})\n",
    "model_2 = load_model('light_weight_unet_gaze_estimation_model.h5', custom_objects={'dice_loss': dice_loss})\n",
    "\n",
    "# print(calculate_gaze_vector_image('/home/yasas/GazeEstimation/openEDS/openEDS/test/images/000170.png', model , resize= False))\n",
    "print(calculate_gaze_vector_image('/home/yasas/GazeEstimation/openEDS/openEDS/test/images/000000.png', model_2, resize= True))\n",
    "# skip = 741\n",
    "\n",
    "directions = {}\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(image_dir_path, image_file)\n",
    "    print(image_path)\n",
    "    print(f\"Processing {image_path}...\")\n",
    "    direction_vector = calculate_gaze_vector_image(image_path, model)\n",
    "    if(direction_vector is None):\n",
    "        direction_vector = np.array([0, 0])\n",
    "    else:\n",
    "        direction_vector = np.array(direction_vector)\n",
    "        norm = np.linalg.norm(direction_vector)\n",
    "        if norm != 0:\n",
    "            direction_vector = direction_vector / norm\n",
    "    directions[image_path.split('/')[-1]] = direction_vector\n",
    "    with open(\"directions.txt\", \"a\") as file:\n",
    "        file.write(f\"{image_path.split('/')[-1]}: {direction_vector.tolist()}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a21c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leftmost Point: (np.int32(32), np.int32(99))\n",
      "Rightmost Point: (np.int32(109), np.int32(83))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -8 -16]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "def calculate_gaze_vector_from_lable_img(label_path):\n",
    "    label = np.load(label_path)\n",
    "    label = cv2.resize(label, (128, 128))\n",
    "    label = label / np.max(label)\n",
    "\n",
    "    scalar_lower_bound = 0.2\n",
    "    scalar_upper_bound = 0.5\n",
    "    scalar_region_mask = np.logical_and(label >= scalar_lower_bound, label <= scalar_upper_bound).astype(np.uint8)\n",
    "\n",
    "    iris_lower_bound = 0.75\n",
    "    iris_upper_bound = 1\n",
    "    iris_region_mask = np.logical_and(label >= iris_lower_bound, label <= iris_upper_bound).astype(np.uint8)\n",
    "\n",
    "    # Find contours from the binary mask\n",
    "    unfiltered_scalar_contours, _ = cv2.findContours(scalar_region_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    iris_contours, _ = cv2.findContours(iris_region_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(iris_contours) == 0:\n",
    "        print(\"No iris contours found.\")\n",
    "        return None\n",
    "\n",
    "    scalar_contours = [cnt for cnt in unfiltered_scalar_contours if cv2.contourArea(cnt) > 25]\n",
    "\n",
    "    # Find the iris contour with the largest area\n",
    "    largest_iris_contour = max(iris_contours, key=cv2.contourArea)\n",
    "\n",
    "    M = cv2.moments(largest_iris_contour)\n",
    "\n",
    "    if M[\"m00\"] != 0:\n",
    "        center_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        center_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        # fallback if the area is too small\n",
    "        center_x, center_y = 0, 0\n",
    "\n",
    "    iris_center = (center_x, center_y)\n",
    "\n",
    "    # Initialize leftmost and rightmost points\n",
    "    leftmost = (128, 128)\n",
    "    rightmost = (0, 0)\n",
    "\n",
    "    # Find extreme points from all contours\n",
    "    for contour in scalar_contours:\n",
    "        for point in contour:\n",
    "            x, y = point[0]\n",
    "            if x < leftmost[0]:\n",
    "                leftmost = (x, y)\n",
    "            if x > rightmost[0]:\n",
    "                rightmost = (x, y)\n",
    "\n",
    "    print(f\"Leftmost Point: {leftmost}\")\n",
    "    print(f\"Rightmost Point: {rightmost}\")\n",
    "\n",
    "    scelar_vector =  np.array(rightmost) - np.array(leftmost)\n",
    "    middle_point = ((leftmost[0] + rightmost[0]) // 2, (leftmost[1] + rightmost[1]) // 2)\n",
    "    # Convert predicted mask to RGB to draw colored circles\n",
    "    predicted_mask_rgb = cv2.cvtColor((label * 255).astype(np.uint8), cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # Draw circles at leftmost and rightmost points\n",
    "    cv2.circle(predicted_mask_rgb, leftmost, radius=2, color=(255, 0, 0), thickness=-1)  # Blue circle\n",
    "    cv2.circle(predicted_mask_rgb, rightmost, radius=2, color=(0, 0, 255), thickness=-1) # Red circle\n",
    "    cv2.circle(predicted_mask_rgb, iris_center, radius=2, color=(0, 255, 255), thickness=-1) # Red circle\n",
    "    cv2.circle(predicted_mask_rgb, middle_point, radius=2, color=(225, 0, 255), thickness=-1)  # Magenta circle\n",
    "    cv2.line(predicted_mask_rgb, leftmost, rightmost, color=(0, 255, 0), thickness=1)\n",
    "    cv2.arrowedLine(predicted_mask_rgb, middle_point, iris_center, color=(255, 0, 0), thickness=1, tipLength=0.5)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(predicted_mask_rgb)\n",
    "    plt.title('Predicted Mask with Circles')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    iris_center_vector = np.array(iris_center)\n",
    "    middle_point_vector = np.array(middle_point)\n",
    "    return iris_center_vector - middle_point_vector\n",
    "\n",
    "\n",
    "image_label_path =  '/home/yasas/GazeEstimation/openEDS/openEDS/test/labels'\n",
    "print(calculate_gaze_vector_from_lable_img('/home/yasas/GazeEstimation/openEDS/openEDS/test/labels/001000.npy'))\n",
    "\n",
    "image_files = sorted(os.listdir(image_label_path))\n",
    "\n",
    "\n",
    "# for image_file in image_files:\n",
    "#     image_path = os.path.join(image_label_path, image_file)\n",
    "#     print(image_path)\n",
    "#     print(f\"Processing {image_path}...\")\n",
    "#     calculate_gaze_vector_from_lable_img(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
